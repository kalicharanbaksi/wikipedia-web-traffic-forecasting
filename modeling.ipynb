{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Colab_25GBRAM_GPU_Techhawa_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqEcar6duzbo",
        "outputId": "f40deeeb-b007-4453-c446-b9749582a1b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2hMFp5Du4m_",
        "outputId": "02668f98-a032-4d05-de43-a2ebc81aa1df"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N72UAdyHu4sW",
        "outputId": "0a6f5b3f-7214-4990-e5b4-277889d0c18e"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Kaggle'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO_6kDssu_7G"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.dates import MonthLocator\n",
        "import datetime as dt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from random import randint"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "OfE57Fb9u_9h",
        "outputId": "2388eefa-5a7f-41ed-a5f8-6f6b4d371647"
      },
      "source": [
        "data=pd.read_csv(\"train_2.csv.zip\").fillna(0)\n",
        "data=data.interpolate(method ='linear',limit=1)\n",
        "data = data.fillna(0)\n",
        "data.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page</th>\n",
              "      <th>2015-07-01</th>\n",
              "      <th>2015-07-02</th>\n",
              "      <th>2015-07-03</th>\n",
              "      <th>2015-07-04</th>\n",
              "      <th>2015-07-05</th>\n",
              "      <th>2015-07-06</th>\n",
              "      <th>2015-07-07</th>\n",
              "      <th>2015-07-08</th>\n",
              "      <th>2015-07-09</th>\n",
              "      <th>2015-07-10</th>\n",
              "      <th>2015-07-11</th>\n",
              "      <th>2015-07-12</th>\n",
              "      <th>2015-07-13</th>\n",
              "      <th>2015-07-14</th>\n",
              "      <th>2015-07-15</th>\n",
              "      <th>2015-07-16</th>\n",
              "      <th>2015-07-17</th>\n",
              "      <th>2015-07-18</th>\n",
              "      <th>2015-07-19</th>\n",
              "      <th>2015-07-20</th>\n",
              "      <th>2015-07-21</th>\n",
              "      <th>2015-07-22</th>\n",
              "      <th>2015-07-23</th>\n",
              "      <th>2015-07-24</th>\n",
              "      <th>2015-07-25</th>\n",
              "      <th>2015-07-26</th>\n",
              "      <th>2015-07-27</th>\n",
              "      <th>2015-07-28</th>\n",
              "      <th>2015-07-29</th>\n",
              "      <th>2015-07-30</th>\n",
              "      <th>2015-07-31</th>\n",
              "      <th>2015-08-01</th>\n",
              "      <th>2015-08-02</th>\n",
              "      <th>2015-08-03</th>\n",
              "      <th>2015-08-04</th>\n",
              "      <th>2015-08-05</th>\n",
              "      <th>2015-08-06</th>\n",
              "      <th>2015-08-07</th>\n",
              "      <th>2015-08-08</th>\n",
              "      <th>...</th>\n",
              "      <th>2017-08-02</th>\n",
              "      <th>2017-08-03</th>\n",
              "      <th>2017-08-04</th>\n",
              "      <th>2017-08-05</th>\n",
              "      <th>2017-08-06</th>\n",
              "      <th>2017-08-07</th>\n",
              "      <th>2017-08-08</th>\n",
              "      <th>2017-08-09</th>\n",
              "      <th>2017-08-10</th>\n",
              "      <th>2017-08-11</th>\n",
              "      <th>2017-08-12</th>\n",
              "      <th>2017-08-13</th>\n",
              "      <th>2017-08-14</th>\n",
              "      <th>2017-08-15</th>\n",
              "      <th>2017-08-16</th>\n",
              "      <th>2017-08-17</th>\n",
              "      <th>2017-08-18</th>\n",
              "      <th>2017-08-19</th>\n",
              "      <th>2017-08-20</th>\n",
              "      <th>2017-08-21</th>\n",
              "      <th>2017-08-22</th>\n",
              "      <th>2017-08-23</th>\n",
              "      <th>2017-08-24</th>\n",
              "      <th>2017-08-25</th>\n",
              "      <th>2017-08-26</th>\n",
              "      <th>2017-08-27</th>\n",
              "      <th>2017-08-28</th>\n",
              "      <th>2017-08-29</th>\n",
              "      <th>2017-08-30</th>\n",
              "      <th>2017-08-31</th>\n",
              "      <th>2017-09-01</th>\n",
              "      <th>2017-09-02</th>\n",
              "      <th>2017-09-03</th>\n",
              "      <th>2017-09-04</th>\n",
              "      <th>2017-09-05</th>\n",
              "      <th>2017-09-06</th>\n",
              "      <th>2017-09-07</th>\n",
              "      <th>2017-09-08</th>\n",
              "      <th>2017-09-09</th>\n",
              "      <th>2017-09-10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>46.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>35.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 804 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Page  ...  2017-09-10\n",
              "0            2NE1_zh.wikipedia.org_all-access_spider  ...        38.0\n",
              "1             2PM_zh.wikipedia.org_all-access_spider  ...        81.0\n",
              "2              3C_zh.wikipedia.org_all-access_spider  ...         6.0\n",
              "3         4minute_zh.wikipedia.org_all-access_spider  ...         4.0\n",
              "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  ...         7.0\n",
              "\n",
              "[5 rows x 804 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b17h2MbTvAAg",
        "outputId": "c6893f92-c7fd-48ff-ea56-1e6307a4af99"
      },
      "source": [
        "#outlier removal\n",
        "col=data.columns\n",
        "for i in tqdm(range(data.shape[0])):\n",
        "    temp=data.iloc[i].values[1:]\n",
        "    thres=np.percentile(temp,99.8)\n",
        "    med=np.median(temp)\n",
        "    for j in col[1:]:\n",
        "        if(data.at[i,j]>thres):\n",
        "            data.at[i,j]=med\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [14:37<00:00, 165.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY8cb4S9u4vO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "41c824f3-f5ee-44db-c553-03813aa0172c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page</th>\n",
              "      <th>2015-07-01</th>\n",
              "      <th>2015-07-02</th>\n",
              "      <th>2015-07-03</th>\n",
              "      <th>2015-07-04</th>\n",
              "      <th>2015-07-05</th>\n",
              "      <th>2015-07-06</th>\n",
              "      <th>2015-07-07</th>\n",
              "      <th>2015-07-08</th>\n",
              "      <th>2015-07-09</th>\n",
              "      <th>2015-07-10</th>\n",
              "      <th>2015-07-11</th>\n",
              "      <th>2015-07-12</th>\n",
              "      <th>2015-07-13</th>\n",
              "      <th>2015-07-14</th>\n",
              "      <th>2015-07-15</th>\n",
              "      <th>2015-07-16</th>\n",
              "      <th>2015-07-17</th>\n",
              "      <th>2015-07-18</th>\n",
              "      <th>2015-07-19</th>\n",
              "      <th>2015-07-20</th>\n",
              "      <th>2015-07-21</th>\n",
              "      <th>2015-07-22</th>\n",
              "      <th>2015-07-23</th>\n",
              "      <th>2015-07-24</th>\n",
              "      <th>2015-07-25</th>\n",
              "      <th>2015-07-26</th>\n",
              "      <th>2015-07-27</th>\n",
              "      <th>2015-07-28</th>\n",
              "      <th>2015-07-29</th>\n",
              "      <th>2015-07-30</th>\n",
              "      <th>2015-07-31</th>\n",
              "      <th>2015-08-01</th>\n",
              "      <th>2015-08-02</th>\n",
              "      <th>2015-08-03</th>\n",
              "      <th>2015-08-04</th>\n",
              "      <th>2015-08-05</th>\n",
              "      <th>2015-08-06</th>\n",
              "      <th>2015-08-07</th>\n",
              "      <th>2015-08-08</th>\n",
              "      <th>...</th>\n",
              "      <th>2017-08-02</th>\n",
              "      <th>2017-08-03</th>\n",
              "      <th>2017-08-04</th>\n",
              "      <th>2017-08-05</th>\n",
              "      <th>2017-08-06</th>\n",
              "      <th>2017-08-07</th>\n",
              "      <th>2017-08-08</th>\n",
              "      <th>2017-08-09</th>\n",
              "      <th>2017-08-10</th>\n",
              "      <th>2017-08-11</th>\n",
              "      <th>2017-08-12</th>\n",
              "      <th>2017-08-13</th>\n",
              "      <th>2017-08-14</th>\n",
              "      <th>2017-08-15</th>\n",
              "      <th>2017-08-16</th>\n",
              "      <th>2017-08-17</th>\n",
              "      <th>2017-08-18</th>\n",
              "      <th>2017-08-19</th>\n",
              "      <th>2017-08-20</th>\n",
              "      <th>2017-08-21</th>\n",
              "      <th>2017-08-22</th>\n",
              "      <th>2017-08-23</th>\n",
              "      <th>2017-08-24</th>\n",
              "      <th>2017-08-25</th>\n",
              "      <th>2017-08-26</th>\n",
              "      <th>2017-08-27</th>\n",
              "      <th>2017-08-28</th>\n",
              "      <th>2017-08-29</th>\n",
              "      <th>2017-08-30</th>\n",
              "      <th>2017-08-31</th>\n",
              "      <th>2017-09-01</th>\n",
              "      <th>2017-09-02</th>\n",
              "      <th>2017-09-03</th>\n",
              "      <th>2017-09-04</th>\n",
              "      <th>2017-09-05</th>\n",
              "      <th>2017-09-06</th>\n",
              "      <th>2017-09-07</th>\n",
              "      <th>2017-09-08</th>\n",
              "      <th>2017-09-09</th>\n",
              "      <th>2017-09-10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>46.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>35.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 804 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Page  ...  2017-09-10\n",
              "0            2NE1_zh.wikipedia.org_all-access_spider  ...        38.0\n",
              "1             2PM_zh.wikipedia.org_all-access_spider  ...        81.0\n",
              "2              3C_zh.wikipedia.org_all-access_spider  ...         6.0\n",
              "3         4minute_zh.wikipedia.org_all-access_spider  ...         4.0\n",
              "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  ...         7.0\n",
              "\n",
              "[5 rows x 804 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDmHLeGXvhwL"
      },
      "source": [
        "pages=data[\"Page\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MUoJaSy-Xtr"
      },
      "source": [
        "Page_name=data[\"Page\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0fuEtyvvo6W"
      },
      "source": [
        "#code for adding language,project,accesstype,agent feature  for last 31 days.\n",
        "project=[]\n",
        "access=[]\n",
        "agent=[]\n",
        "language=[]\n",
        "for i in range(len(pages)):\n",
        "  temp=pages[i].split(\".\")\n",
        "  for j in range(15):\n",
        "    project.append(temp[-2])\n",
        "  k=temp[-3].split(\"_\")\n",
        "  for j in range(15):\n",
        "    language.append(k[-1])\n",
        "  t=temp[-1].split(\"_\")\n",
        "  for j in range(15):\n",
        "    access.append(t[1])\n",
        "    agent.append(t[2])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaERzGXyvo9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd621b6-b360-4b8a-a44b-36dea980ab0c"
      },
      "source": [
        "#weekly trend that was found in auto correlation plot.\n",
        "weekly_trend=[]\n",
        "for i in tqdm(range(data.shape[0])):\n",
        "    temp=data.iloc[i].values\n",
        "    weekly_temp=[]\n",
        "    for j in range(789,804):\n",
        "        weekly_temp.append(temp[j-7])\n",
        "    weekly_trend.extend(weekly_temp) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [01:30<00:00, 1595.14it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5NYrjrvgsWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82616dd-f845-476c-f149-0144634b302a"
      },
      "source": [
        "lag_14_feature=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    temp=data.iloc[i].values\r\n",
        "    weekly_temp=[]\r\n",
        "    for j in range(789,804):\r\n",
        "        weekly_temp.append(temp[j-14])\r\n",
        "    lag_14_feature.extend(weekly_temp) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [01:29<00:00, 1617.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYT08oeShZ8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e237dd00-7ba4-4555-89e5-a93c192c971e"
      },
      "source": [
        "lag_21_feature=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    temp=data.iloc[i].values\r\n",
        "    weekly_temp=[]\r\n",
        "    for j in range(789,804):\r\n",
        "        weekly_temp.append(temp[j-14])\r\n",
        "    lag_21_feature.extend(weekly_temp) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [01:29<00:00, 1624.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNNy-nEPNPMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bceb28a-a63e-48ea-c5b1-495c3fa67de8"
      },
      "source": [
        "monthly_trend=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    temp=data.iloc[i].values\r\n",
        "    monthly_temp=[]\r\n",
        "    for j in range(789,804):\r\n",
        "      monthly_temp_m=[]\r\n",
        "      monthly_temp_m.append(np.median([temp[j-30],temp[j-31]]))\r\n",
        "      monthly_temp_m.append(np.median([temp[j-60],temp[j-61]]))\r\n",
        "      monthly_temp_m.append(np.median([temp[j-90],temp[j-91]]))\r\n",
        "      monthly_temp.append(np.mean(monthly_temp_m))\r\n",
        "    monthly_trend.extend(monthly_temp) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [09:10<00:00, 263.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPm2YimfOic6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea5de71-ac27-46a2-ebd1-3c520d3b9aa9"
      },
      "source": [
        "yearly_trend=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    temp=data.iloc[i].values\r\n",
        "    yearly_temp=[]\r\n",
        "    for j in range(789,804):   \r\n",
        "      yearly_temp_m=[]\r\n",
        "      yearly_temp_m.append(np.median([temp[j-364],temp[j-365],temp[j-366]]))\r\n",
        "      yearly_temp_m.append(np.median([temp[j-729],temp[j-730],temp[j-731]]))\r\n",
        "      yearly_temp.append(np.mean(yearly_temp_m))\r\n",
        "    yearly_trend.extend(yearly_temp)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [06:56<00:00, 348.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61cubFQNvtmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f10ba30-d46b-4671-92f3-318f57e92e77"
      },
      "source": [
        "\n",
        "quarterly_trend=[]\n",
        "for i in tqdm(range(data.shape[0])):\n",
        "    temp=data.iloc[i].values\n",
        "    quarterly_temp=[]\n",
        "    for j in range(789,804):\n",
        "      quarterly_temp_m=[]\n",
        "      quarterly_temp_m.append(np.median([temp[j-119],temp[j-120],temp[j-121]]))\n",
        "      quarterly_temp_m.append(np.median([temp[j-229],temp[j-230],temp[j-231]]))\n",
        "      quarterly_temp_m.append(np.median([temp[j-339],temp[j-340],temp[j-341]]))\n",
        "      quarterly_temp.append(np.mean(quarterly_temp_m))\n",
        "    quarterly_trend.extend(quarterly_temp)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [08:51<00:00, 272.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqqy761nvtqf"
      },
      "source": [
        "y=[]\n",
        "for i in (range(data.shape[0])):\n",
        "    temp=data.iloc[i].values\n",
        "    for j in range(789,804):\n",
        "        y.append(temp[j]) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQdJ3g_8vttN"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder,normalize\n",
        "enc_access= OneHotEncoder(sparse=False)\n",
        "access_ohe=enc_access.fit_transform(np.array(access).reshape(-1,1))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKokN1Lxv1Eu"
      },
      "source": [
        "enc_project= OneHotEncoder(sparse=False)\n",
        "project_ohe=enc_project.fit_transform(np.array(project).reshape(-1,1))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9SZgjFlv1H_"
      },
      "source": [
        "enc_agent= OneHotEncoder(sparse=False)\n",
        "agent_ohe=enc_agent.fit_transform(np.array(agent).reshape(-1,1))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsW86o-ev1Ki"
      },
      "source": [
        "enc_language= OneHotEncoder(sparse=False)\n",
        "language_ohe=enc_language.fit_transform(np.array(language).reshape(-1,1))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UER7mgCwOJj5"
      },
      "source": [
        "#weekday of each day.\r\n",
        "import datetime\r\n",
        "l=len(data.columns)\r\n",
        "weekday=[]\r\n",
        "for i in range(data.shape[0]):\r\n",
        "    week=[]\r\n",
        "    for i in (data.columns[789:804]):\r\n",
        "        temp=i.split('-')\r\n",
        "        my_date=datetime.date(int(temp[0]),int(temp[1]),int(temp[2]))\r\n",
        "        week.append(my_date.weekday())\r\n",
        "    weekday.extend(week)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3cdRZSuMx8_"
      },
      "source": [
        "enc_weekday= OneHotEncoder(sparse=False)\n",
        "weekday_ohe=enc_weekday.fit_transform(np.array(weekday).reshape(-1,1))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOaYOGz4Mx8_",
        "outputId": "e637e7f8-9126-4525-91ac-e961155be084"
      },
      "source": [
        "weekday_ohe.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2175945, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6tgR8SRzbYa",
        "outputId": "5b651ed4-6691-4465-be2b-6a5a424358ce"
      },
      "source": [
        "rolling_median_7=[]\r\n",
        "rolling_mean_7=[]\r\n",
        "rolling_std_7=[]\r\n",
        "rolling_max_7=[]\r\n",
        "rolling_min_7=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "  temp=data.iloc[i].values[782:804]\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_median_7\"]=k.rolling(7).median()\r\n",
        "  rolling_median_7.append(k[\"rolling_median_7\"].values[7:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_mean_7\"]=k.rolling(7,min_periods=1).mean()\r\n",
        "  rolling_mean_7.append(k[\"rolling_mean_7\"].values[7:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_std_7\"]=k.rolling(7,min_periods=1).std()\r\n",
        "  rolling_std_7.append(k[\"rolling_std_7\"].values[7:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_max_7\"]=k.rolling(7,min_periods=1).max()\r\n",
        "  rolling_max_7.append(k[\"rolling_max_7\"].values[7:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_min_7\"]=k.rolling(7,min_periods=1).min()\r\n",
        "  rolling_min_7.append(k[\"rolling_min_7\"].values[7:])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [23:28<00:00, 103.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1i_5xRIIRKR",
        "outputId": "6b0ace48-bc40-423c-cdbc-47c490ad7df7"
      },
      "source": [
        "rolling_median_3=[]\r\n",
        "rolling_mean_3=[]\r\n",
        "rolling_std_3=[]\r\n",
        "rolling_max_3=[]\r\n",
        "rolling_min_3=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "  temp=data.iloc[i].values[786:804]\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_median_3\"]=k.rolling(3).median()\r\n",
        "  rolling_median_3.append(k[\"rolling_median_3\"].values[3:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_mean_3\"]=k.rolling(3,min_periods=1).mean()\r\n",
        "  rolling_mean_3.append(k[\"rolling_mean_3\"].values[3:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_std_3\"]=k.rolling(3,min_periods=1).std()\r\n",
        "  rolling_std_3.append(k[\"rolling_std_3\"].values[3:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_max_3\"]=k.rolling(3,min_periods=1).max()\r\n",
        "  rolling_max_3.append(k[\"rolling_max_3\"].values[3:])\r\n",
        "  k=pd.DataFrame(temp)\r\n",
        "  k[\"rolling_min_3\"]=k.rolling(3,min_periods=1).min()\r\n",
        "  rolling_min_3.append(k[\"rolling_min_3\"].values[3:])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [23:39<00:00, 102.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDYrbwN7fgyq"
      },
      "source": [
        "weekly_trend=normalize(np.array(weekly_trend).reshape(-1,1),axis=0)\r\n",
        "lag_14_feature=normalize(np.array(lag_14_feature).reshape(-1,1),axis=0)\r\n",
        "lag_21_feature=normalize(np.array(lag_21_feature).reshape(-1,1),axis=0)\r\n",
        "monthly_trend=normalize(np.array(monthly_trend).reshape(-1,1),axis=0)\r\n",
        "quarterly_trend=normalize(np.array(quarterly_trend).reshape(-1,1),axis=0)\r\n",
        "yearly_trend=normalize(np.array(yearly_trend).reshape(-1,1),axis=0)\r\n",
        "rolling_median_7=normalize(np.array(rolling_median_7).reshape(-1,1),axis=0)\r\n",
        "rolling_mean_7=normalize(np.array(rolling_mean_7).reshape(-1,1),axis=0)\r\n",
        "rolling_std_7=normalize(np.array(rolling_std_7).reshape(-1,1),axis=0)\r\n",
        "rolling_max_7=normalize(np.array(rolling_max_7).reshape(-1,1),axis=0)\r\n",
        "rolling_min_7=normalize(np.array(rolling_min_7).reshape(-1,1),axis=0)\r\n",
        "rolling_median_3=normalize(np.array(rolling_median_3).reshape(-1,1),axis=0)\r\n",
        "rolling_mean_3=normalize(np.array(rolling_mean_3).reshape(-1,1),axis=0)\r\n",
        "rolling_std_3=normalize(np.array(rolling_std_3).reshape(-1,1),axis=0)\r\n",
        "rolling_max_3=normalize(np.array(rolling_max_3).reshape(-1,1),axis=0)\r\n",
        "rolling_min_3=normalize(np.array(rolling_min_3).reshape(-1,1),axis=0)\r\n",
        "y_value=np.array(y)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl9yrgC3v9SI",
        "outputId": "580d65aa-a001-4d64-8141-83fc60fa5576"
      },
      "source": [
        "print(quarterly_trend.shape)\n",
        "print(monthly_trend.shape)\n",
        "print(yearly_trend.shape)\n",
        "print(weekly_trend.shape)\n",
        "print(agent_ohe.shape)\n",
        "print(project_ohe.shape)\n",
        "print(agent_ohe.shape)\n",
        "print(language_ohe.shape)\n",
        "#print(median.shape)\n",
        "print(weekday_ohe.shape)\n",
        "print(y_value.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2175945, 1)\n",
            "(2175945, 1)\n",
            "(2175945, 1)\n",
            "(2175945, 1)\n",
            "(2175945, 2)\n",
            "(2175945, 3)\n",
            "(2175945, 2)\n",
            "(2175945, 9)\n",
            "(2175945, 7)\n",
            "(2175945,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDxPJQ_Xv_BO"
      },
      "source": [
        "X=np.column_stack((weekly_trend,lag_14_feature,lag_21_feature,quarterly_trend,monthly_trend,yearly_trend,language_ohe,agent_ohe,project_ohe,access_ohe,weekday_ohe,rolling_median_7,rolling_mean_7,rolling_std_7,rolling_max_7,rolling_min_7,rolling_median_3,rolling_mean_3,rolling_std_3,rolling_max_3,rolling_min_3))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAsjS2BeMx9B",
        "outputId": "eee03764-a6e3-42c0-c63b-1ed8652e562f"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2175945, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hobHVHV4wBB-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_value, test_size=0.33, random_state=42)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9zxMoV8wBE2",
        "outputId": "56587a0a-2845-473e-872d-220ecfa9f22e"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1457883, 40)\n",
            "(718062, 40)\n",
            "(1457883,)\n",
            "(718062,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIa-oSBNwJxx"
      },
      "source": [
        "def smape(A, F):\n",
        "    tmp = 2 * np.abs(F - A) / (np.abs(A) + np.abs(F))\n",
        "    len_ = np.count_nonzero(~np.isnan(tmp))\n",
        "    return 1 / len_ * np.nansum(tmp)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52PghdSvQiY"
      },
      "source": [
        "<h1>Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzK0sM7UwBHl"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "pred=reg.predict(X_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwA9QrojwMUn",
        "outputId": "8518256a-7003-40ab-bc30-7a7651deb7b7"
      },
      "source": [
        "smape_loss=smape(y_test,pred)\n",
        "print('smape loss in LinearRegression is: ',smape_loss)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "smape loss in LinearRegression is:  0.7854155326031005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO_S9psKvLpI"
      },
      "source": [
        "<h1>GBDT<h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7URALzQsP_NJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c079f3-806e-4ee7-bb79-18bd3153ed50"
      },
      "source": [
        "#hyper parameter tuning\r\n",
        "from xgboost import XGBRegressor\r\n",
        "max_depth=[9,11,13,15]\r\n",
        "n_estimators=[200,250,300,500]\r\n",
        "loss=9999999\r\n",
        "for i in tqdm(max_depth):\r\n",
        "  for j in n_estimators:\r\n",
        "    reg=XGBRegressor(max_depth=i,n_jobs=-1,n_estimators=j,tree_method=\"gpu_hist\")\r\n",
        "    reg.fit(X_train,y_train)\r\n",
        "    pred=reg.predict(X_test)\r\n",
        "    score=smape(y_test,pred)\r\n",
        "    print(\"max_depth=\",i)\r\n",
        "    print(\"n_estimator=\",j)\r\n",
        "    print(\"smape=\",score)\r\n",
        "    print(\"-\"*50)\r\n",
        "    if score<loss:\r\n",
        "      loss=score\r\n",
        "      d=i\r\n",
        "      n=j\r\n",
        "    print(\"best parameters till now\")\r\n",
        "    print(\"max depth=\",d,\",n_estimator=\",n,\",loss=\",loss)\r\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:15:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 9\n",
            "n_estimator= 200\n",
            "smape= 0.2773226880660799\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 9 ,n_estimator= 200 ,loss= 0.2773226880660799\n",
            "--------------------------------------------------\n",
            "[07:15:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 9\n",
            "n_estimator= 250\n",
            "smape= 0.276628549906074\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 9 ,n_estimator= 250 ,loss= 0.276628549906074\n",
            "--------------------------------------------------\n",
            "[07:16:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 9\n",
            "n_estimator= 300\n",
            "smape= 0.275769648381841\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 9 ,n_estimator= 300 ,loss= 0.275769648381841\n",
            "--------------------------------------------------\n",
            "[07:16:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 1/4 [01:44<05:12, 104.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_depth= 9\n",
            "n_estimator= 500\n",
            "smape= 0.2717309207112899\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 9 ,n_estimator= 500 ,loss= 0.2717309207112899\n",
            "--------------------------------------------------\n",
            "[07:17:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 11\n",
            "n_estimator= 200\n",
            "smape= 0.25831428611505136\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 11 ,n_estimator= 200 ,loss= 0.25831428611505136\n",
            "--------------------------------------------------\n",
            "[07:17:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 11\n",
            "n_estimator= 250\n",
            "smape= 0.25657619827607536\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 11 ,n_estimator= 250 ,loss= 0.25657619827607536\n",
            "--------------------------------------------------\n",
            "[07:18:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 11\n",
            "n_estimator= 300\n",
            "smape= 0.2552376351556614\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 11 ,n_estimator= 300 ,loss= 0.2552376351556614\n",
            "--------------------------------------------------\n",
            "[07:18:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 2/4 [04:22<04:00, 120.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_depth= 11\n",
            "n_estimator= 500\n",
            "smape= 0.25460987779367805\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 11 ,n_estimator= 500 ,loss= 0.25460987779367805\n",
            "--------------------------------------------------\n",
            "[07:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 13\n",
            "n_estimator= 200\n",
            "smape= 0.25149677195840847\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 13 ,n_estimator= 200 ,loss= 0.25149677195840847\n",
            "--------------------------------------------------\n",
            "[07:20:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 13\n",
            "n_estimator= 250\n",
            "smape= 0.25042475574369905\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 13 ,n_estimator= 250 ,loss= 0.25042475574369905\n",
            "--------------------------------------------------\n",
            "[07:21:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 13\n",
            "n_estimator= 300\n",
            "smape= 0.2504110553747725\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 13 ,n_estimator= 300 ,loss= 0.2504110553747725\n",
            "--------------------------------------------------\n",
            "[07:22:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [09:05<02:49, 169.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_depth= 13\n",
            "n_estimator= 500\n",
            "smape= 0.24860083910580702\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 13 ,n_estimator= 500 ,loss= 0.24860083910580702\n",
            "--------------------------------------------------\n",
            "[07:24:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 15\n",
            "n_estimator= 200\n",
            "smape= 0.24779484443431846\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 15 ,n_estimator= 200 ,loss= 0.24779484443431846\n",
            "--------------------------------------------------\n",
            "[07:26:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 15\n",
            "n_estimator= 250\n",
            "smape= 0.24702215016138038\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 15 ,n_estimator= 250 ,loss= 0.24702215016138038\n",
            "--------------------------------------------------\n",
            "[07:28:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "max_depth= 15\n",
            "n_estimator= 300\n",
            "smape= 0.24645005027203207\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 15 ,n_estimator= 300 ,loss= 0.24645005027203207\n",
            "--------------------------------------------------\n",
            "[07:30:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [18:33<00:00, 278.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_depth= 15\n",
            "n_estimator= 500\n",
            "smape= 0.24457808823213364\n",
            "--------------------------------------------------\n",
            "best parameters till now\n",
            "max depth= 15 ,n_estimator= 500 ,loss= 0.24457808823213364\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZIG7LovK7iG"
      },
      "source": [
        "from xgboost import XGBRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehZGvZfMQ2By",
        "outputId": "134f2433-7aff-4395-9e38-4815d032a94f"
      },
      "source": [
        "from xgboost import XGBRegressor\r\n",
        "reg=XGBRegressor(max_depth=15,n_jobs=-1,n_estimators=300,tree_method=\"gpu_hist\")\r\n",
        "reg.fit(X_train,y_train)\r\n",
        "pred=reg.predict(X_test)\r\n",
        "score=smape(y_test,pred)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[07:34:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYLvAKprBhkU",
        "outputId": "657bd490-c69d-499f-91b9-d70a2a4b2dda"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24663706187287127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bi8o2O7vYeh"
      },
      "source": [
        "<h1>note</h1>\r\n",
        "\r\n",
        "1. the reason for not trying more ML models such as randomforest,decision tree,svm regressor is as ML models are purely dependent on feature engineering and as we are predicting for next 62 days in future we have to use the predicted data for feature engineering.so its useless to use ML moels as the error is increasing exponetially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwIaQef6KNbr"
      },
      "source": [
        "new_data=data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI9_IugeVmIP"
      },
      "source": [
        "#preparing prediction data for generating submission file\r\n",
        "import tqdm.notebook as tq\r\n",
        "date=datetime.date(2017,9,11)\r\n",
        "pred=np.zeros((64,145063))\r\n",
        "for j in tq.tqdm(range(64)):\r\n",
        "  quarterly_trend=[]\r\n",
        "  quarterly_temp_m=[]\r\n",
        "  monthly_temp_m=[]\r\n",
        "  monthly_trend=[]\r\n",
        "  yearly_trend=[]\r\n",
        "  yearly_temp_m=[]\r\n",
        "  weekly_trend=[]\r\n",
        "  project=[]\r\n",
        "  access=[]\r\n",
        "  agent=[]\r\n",
        "  lag_14_feature=[]\r\n",
        "  lag_21_feature=[]\r\n",
        "  language=[]\r\n",
        "  rolling_median_7=[]\r\n",
        "  rolling_mean_7=[]\r\n",
        "  rolling_std_7=[]\r\n",
        "  rolling_max_7=[]\r\n",
        "  rolling_min_7=[]\r\n",
        "  rolling_median_3=[]\r\n",
        "  rolling_mean_3=[]\r\n",
        "  rolling_std_3=[]\r\n",
        "  rolling_max_3=[]\r\n",
        "  rolling_min_3=[]\r\n",
        "  current_date=date.weekday()\r\n",
        "  current_date=np.tile(current_date,(data.shape[0],1))\r\n",
        "  weekday_ohe=enc_weekday.transform(np.array([current_date]).reshape(-1,1))\r\n",
        "\r\n",
        "  for i in (range(data.shape[0])):\r\n",
        "      temp=pages[i].split(\".\")\r\n",
        "      project.append(temp[-2])\r\n",
        "      k=temp[-3].split(\"_\")\r\n",
        "      language.append(k[-1])\r\n",
        "      t=temp[-1].split(\"_\")\r\n",
        "      access.append(t[1])\r\n",
        "      agent.append(t[2])\r\n",
        "      #weekly trend\r\n",
        "      temp=new.iloc[i].values\r\n",
        "      weekly_trend.append(temp[-7])\r\n",
        "      #quarterly trend\r\n",
        "      quarterly_temp_m.append(np.median([temp[-119],temp[-120],temp[-121]]))\r\n",
        "      quarterly_temp_m.append(np.median([temp[-229],temp[-230],temp[-231]]))\r\n",
        "      quarterly_temp_m.append(np.median([temp[-339],temp[-340],temp[-341]]))\r\n",
        "      quarterly_trend.append(np.mean(quarterly_temp_m))\r\n",
        "      monthly_temp_m.append(np.median([temp[-30],temp[-31]]))\r\n",
        "      monthly_temp_m.append(np.median([temp[-60],temp[-61]]))\r\n",
        "      monthly_temp_m.append(np.median([temp[-90],temp[-91]]))\r\n",
        "      monthly_trend.append(np.mean(monthly_temp_m))\r\n",
        "      yearly_temp_m.append(np.median([temp[-364],temp[-365],temp[-366]]))\r\n",
        "      yearly_temp_m.append(np.median([temp[-729],temp[-730],temp[-731]]))\r\n",
        "      yearly_temp.append(np.mean(yearly_temp_m))\r\n",
        "      lag_14_feature.append(temp[-14])\r\n",
        "      lag_21_feature.append(temp[-21])\r\n",
        "      t=temp[-7:]\r\n",
        "      rolling_median_7.append(np.median(t))\r\n",
        "      rolling_mean_7.append(np.mean(t))\r\n",
        "      rolling_std_7.append(np.std(t))\r\n",
        "      rolling_max_7.append(np.max(t))\r\n",
        "      rolling_min_7.append(np.min(t))\r\n",
        "      t=temp[-3:]\r\n",
        "      rolling_median_3.append(np.median(t))\r\n",
        "      rolling_mean_3.append(np.mean(t))\r\n",
        "      rolling_std_3.append(np.std(t))\r\n",
        "      rolling_max_3.append(np.max(t))\r\n",
        "      rolling_min_3.append(np.min(t))\r\n",
        "  access_ohe=enc_access.transform(np.array(access).reshape(-1,1))\r\n",
        "  project_ohe=enc_project.transform(np.array(project).reshape(-1,1))\r\n",
        "  agent_ohe=enc_agent.transform(np.array(agent).reshape(-1,1))\r\n",
        "  language_ohe=enc_language.transform(np.array(language).reshape(-1,1))\r\n",
        "  weekly_trend=normalize(np.array(weekly_trend).reshape(-1,1),axis=0)\r\n",
        "  quarterly_trend_120=normalize(np.array(quarterly_trend_120).reshape(-1,1),axis=0)\r\n",
        "  quarterly_trend_230=normalize(np.array(quarterly_trend_230).reshape(-1,1),axis=0)\r\n",
        "  quarterly_trend_340=normalize(np.array(quarterly_trend_340).reshape(-1,1),axis=0)\r\n",
        "  lag_14_feature=normalize(np.array(lag_14_feature).reshape(-1,1),axis=0)\r\n",
        "  lag_21_feature=normalize(np.array(lag_21_feature).reshape(-1,1),axis=0)\r\n",
        "  rolling_median_7=normalize(np.array(rolling_median_7).reshape(-1,1),axis=0)\r\n",
        "  rolling_mean_7=normalize(np.array(rolling_mean_7).reshape(-1,1),axis=0)\r\n",
        "  rolling_std_7=normalize(np.array(rolling_std_7).reshape(-1,1),axis=0)\r\n",
        "  rolling_max_7=normalize(np.array(rolling_max_7).reshape(-1,1),axis=0)\r\n",
        "  rolling_min_7=normalize(np.array(rolling_min_7).reshape(-1,1),axis=0)\r\n",
        "  rolling_median_3=normalize(np.array(rolling_median_3).reshape(-1,1),axis=0)\r\n",
        "  rolling_mean_3=normalize(np.array(rolling_mean_3).reshape(-1,1),axis=0)\r\n",
        "  rolling_std_3=normalize(np.array(rolling_std_3).reshape(-1,1),axis=0)\r\n",
        "  rolling_max_3=normalize(np.array(rolling_max_3).reshape(-1,1),axis=0)\r\n",
        "  rolling_min_3=normalize(np.array(rolling_min_3).reshape(-1,1),axis=0)\r\n",
        "  X_test=np.column_stack((weekly_trend,lag_14_feature,lag_21_feature,quarterly_trend,monthly_trend,yearly_trend,language_ohe,agent_ohe,project_ohe,access_ohe,weekday_ohe,rolling_median_7,rolling_mean_7,rolling_std_7,rolling_max_7,rolling_min_7,rolling_median_3,rolling_mean_3,rolling_std_3,rolling_max_3,rolling_min_3))\r\n",
        "  y_pred=reg.predict(X_test)\r\n",
        "  new_data[str(date)]=pred_value\r\n",
        "  date += datetime.timedelta(days=1)\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rIJgS8NT4INL",
        "outputId": "14018e94-f659-46f7-fffc-ef68cd801a1c"
      },
      "source": [
        "new_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page</th>\n",
              "      <th>2015-07-01</th>\n",
              "      <th>2015-07-02</th>\n",
              "      <th>2015-07-03</th>\n",
              "      <th>2015-07-04</th>\n",
              "      <th>2015-07-05</th>\n",
              "      <th>2015-07-06</th>\n",
              "      <th>2015-07-07</th>\n",
              "      <th>2015-07-08</th>\n",
              "      <th>2015-07-09</th>\n",
              "      <th>2015-07-10</th>\n",
              "      <th>2015-07-11</th>\n",
              "      <th>2015-07-12</th>\n",
              "      <th>2015-07-13</th>\n",
              "      <th>2015-07-14</th>\n",
              "      <th>2015-07-15</th>\n",
              "      <th>2015-07-16</th>\n",
              "      <th>2015-07-17</th>\n",
              "      <th>2015-07-18</th>\n",
              "      <th>2015-07-19</th>\n",
              "      <th>2015-07-20</th>\n",
              "      <th>2015-07-21</th>\n",
              "      <th>2015-07-22</th>\n",
              "      <th>2015-07-23</th>\n",
              "      <th>2015-07-24</th>\n",
              "      <th>2015-07-25</th>\n",
              "      <th>2015-07-26</th>\n",
              "      <th>2015-07-27</th>\n",
              "      <th>2015-07-28</th>\n",
              "      <th>2015-07-29</th>\n",
              "      <th>2015-07-30</th>\n",
              "      <th>2015-07-31</th>\n",
              "      <th>2015-08-01</th>\n",
              "      <th>2015-08-02</th>\n",
              "      <th>2015-08-03</th>\n",
              "      <th>2015-08-04</th>\n",
              "      <th>2015-08-05</th>\n",
              "      <th>2015-08-06</th>\n",
              "      <th>2015-08-07</th>\n",
              "      <th>2015-08-08</th>\n",
              "      <th>...</th>\n",
              "      <th>2017-10-05</th>\n",
              "      <th>2017-10-06</th>\n",
              "      <th>2017-10-07</th>\n",
              "      <th>2017-10-08</th>\n",
              "      <th>2017-10-09</th>\n",
              "      <th>2017-10-10</th>\n",
              "      <th>2017-10-11</th>\n",
              "      <th>2017-10-12</th>\n",
              "      <th>2017-10-13</th>\n",
              "      <th>2017-10-14</th>\n",
              "      <th>2017-10-15</th>\n",
              "      <th>2017-10-16</th>\n",
              "      <th>2017-10-17</th>\n",
              "      <th>2017-10-18</th>\n",
              "      <th>2017-10-19</th>\n",
              "      <th>2017-10-20</th>\n",
              "      <th>2017-10-21</th>\n",
              "      <th>2017-10-22</th>\n",
              "      <th>2017-10-23</th>\n",
              "      <th>2017-10-24</th>\n",
              "      <th>2017-10-25</th>\n",
              "      <th>2017-10-26</th>\n",
              "      <th>2017-10-27</th>\n",
              "      <th>2017-10-28</th>\n",
              "      <th>2017-10-29</th>\n",
              "      <th>2017-10-30</th>\n",
              "      <th>2017-10-31</th>\n",
              "      <th>2017-11-01</th>\n",
              "      <th>2017-11-02</th>\n",
              "      <th>2017-11-03</th>\n",
              "      <th>2017-11-04</th>\n",
              "      <th>2017-11-05</th>\n",
              "      <th>2017-11-06</th>\n",
              "      <th>2017-11-07</th>\n",
              "      <th>2017-11-08</th>\n",
              "      <th>2017-11-09</th>\n",
              "      <th>2017-11-10</th>\n",
              "      <th>2017-11-11</th>\n",
              "      <th>2017-11-12</th>\n",
              "      <th>2017-11-13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>53157.238281</td>\n",
              "      <td>48551.339844</td>\n",
              "      <td>48095.140625</td>\n",
              "      <td>51316.437500</td>\n",
              "      <td>56169.386719</td>\n",
              "      <td>57802.000000</td>\n",
              "      <td>49373.394531</td>\n",
              "      <td>53821.445312</td>\n",
              "      <td>52565.902344</td>\n",
              "      <td>49505.187500</td>\n",
              "      <td>52136.089844</td>\n",
              "      <td>53735.433594</td>\n",
              "      <td>53429.273438</td>\n",
              "      <td>49604.640625</td>\n",
              "      <td>51847.917969</td>\n",
              "      <td>49896.531250</td>\n",
              "      <td>48621.121094</td>\n",
              "      <td>51883.683594</td>\n",
              "      <td>53224.292969</td>\n",
              "      <td>52523.593750</td>\n",
              "      <td>48954.261719</td>\n",
              "      <td>52185.531250</td>\n",
              "      <td>49583.687500</td>\n",
              "      <td>49156.535156</td>\n",
              "      <td>51775.097656</td>\n",
              "      <td>53777.429688</td>\n",
              "      <td>53960.617188</td>\n",
              "      <td>49543.871094</td>\n",
              "      <td>52239.859375</td>\n",
              "      <td>49707.632812</td>\n",
              "      <td>48710.203125</td>\n",
              "      <td>52124.242188</td>\n",
              "      <td>54242.093750</td>\n",
              "      <td>52820.363281</td>\n",
              "      <td>52074.535156</td>\n",
              "      <td>52174.695312</td>\n",
              "      <td>51121.875000</td>\n",
              "      <td>48893.246094</td>\n",
              "      <td>54403.898438</td>\n",
              "      <td>54835.027344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>54435.378906</td>\n",
              "      <td>50110.781250</td>\n",
              "      <td>47672.019531</td>\n",
              "      <td>51590.500000</td>\n",
              "      <td>54874.761719</td>\n",
              "      <td>53851.289062</td>\n",
              "      <td>49802.054688</td>\n",
              "      <td>55084.933594</td>\n",
              "      <td>51295.109375</td>\n",
              "      <td>49535.457031</td>\n",
              "      <td>51476.578125</td>\n",
              "      <td>53688.242188</td>\n",
              "      <td>56224.648438</td>\n",
              "      <td>48640.468750</td>\n",
              "      <td>52462.769531</td>\n",
              "      <td>50862.777344</td>\n",
              "      <td>49679.347656</td>\n",
              "      <td>48533.382812</td>\n",
              "      <td>56536.035156</td>\n",
              "      <td>50827.734375</td>\n",
              "      <td>46087.085938</td>\n",
              "      <td>58726.675781</td>\n",
              "      <td>50871.847656</td>\n",
              "      <td>47310.390625</td>\n",
              "      <td>56857.750000</td>\n",
              "      <td>57980.398438</td>\n",
              "      <td>59316.980469</td>\n",
              "      <td>59390.062500</td>\n",
              "      <td>58101.226562</td>\n",
              "      <td>57958.578125</td>\n",
              "      <td>53179.558594</td>\n",
              "      <td>56911.132812</td>\n",
              "      <td>54698.117188</td>\n",
              "      <td>58213.031250</td>\n",
              "      <td>54066.875000</td>\n",
              "      <td>54325.515625</td>\n",
              "      <td>50844.160156</td>\n",
              "      <td>49922.589844</td>\n",
              "      <td>51557.078125</td>\n",
              "      <td>53051.683594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3031.782715</td>\n",
              "      <td>3050.846680</td>\n",
              "      <td>2998.397705</td>\n",
              "      <td>3473.695312</td>\n",
              "      <td>3857.564209</td>\n",
              "      <td>4229.821289</td>\n",
              "      <td>4478.077148</td>\n",
              "      <td>5084.891113</td>\n",
              "      <td>4955.820801</td>\n",
              "      <td>4928.448242</td>\n",
              "      <td>5474.054199</td>\n",
              "      <td>5960.908203</td>\n",
              "      <td>5834.079590</td>\n",
              "      <td>6619.153809</td>\n",
              "      <td>7197.038574</td>\n",
              "      <td>7417.282227</td>\n",
              "      <td>7585.860840</td>\n",
              "      <td>8340.449219</td>\n",
              "      <td>9463.821289</td>\n",
              "      <td>9992.162109</td>\n",
              "      <td>10632.555664</td>\n",
              "      <td>13945.476562</td>\n",
              "      <td>13464.224609</td>\n",
              "      <td>17904.957031</td>\n",
              "      <td>19766.322266</td>\n",
              "      <td>26520.503906</td>\n",
              "      <td>25131.654297</td>\n",
              "      <td>25565.726562</td>\n",
              "      <td>33599.617188</td>\n",
              "      <td>34929.808594</td>\n",
              "      <td>36870.203125</td>\n",
              "      <td>42885.902344</td>\n",
              "      <td>45481.125000</td>\n",
              "      <td>45933.855469</td>\n",
              "      <td>48131.585938</td>\n",
              "      <td>52441.445312</td>\n",
              "      <td>50806.617188</td>\n",
              "      <td>48671.089844</td>\n",
              "      <td>51059.320312</td>\n",
              "      <td>53472.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
              "      <td>35.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>19786.740234</td>\n",
              "      <td>22497.496094</td>\n",
              "      <td>22494.070312</td>\n",
              "      <td>23791.318359</td>\n",
              "      <td>25772.185547</td>\n",
              "      <td>26230.021484</td>\n",
              "      <td>25311.914062</td>\n",
              "      <td>32734.273438</td>\n",
              "      <td>34060.539062</td>\n",
              "      <td>36744.910156</td>\n",
              "      <td>41502.042969</td>\n",
              "      <td>44708.285156</td>\n",
              "      <td>47610.546875</td>\n",
              "      <td>48712.742188</td>\n",
              "      <td>50989.128906</td>\n",
              "      <td>53074.671875</td>\n",
              "      <td>48041.605469</td>\n",
              "      <td>51115.679688</td>\n",
              "      <td>54125.027344</td>\n",
              "      <td>52727.886719</td>\n",
              "      <td>47902.421875</td>\n",
              "      <td>53667.117188</td>\n",
              "      <td>51944.179688</td>\n",
              "      <td>48727.417969</td>\n",
              "      <td>51264.531250</td>\n",
              "      <td>52914.070312</td>\n",
              "      <td>52812.847656</td>\n",
              "      <td>49467.421875</td>\n",
              "      <td>51916.449219</td>\n",
              "      <td>49661.718750</td>\n",
              "      <td>48430.253906</td>\n",
              "      <td>53584.398438</td>\n",
              "      <td>54606.027344</td>\n",
              "      <td>52956.722656</td>\n",
              "      <td>49910.210938</td>\n",
              "      <td>52150.050781</td>\n",
              "      <td>50058.792969</td>\n",
              "      <td>49021.929688</td>\n",
              "      <td>52269.183594</td>\n",
              "      <td>54516.679688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6641.893066</td>\n",
              "      <td>6661.897461</td>\n",
              "      <td>6826.952148</td>\n",
              "      <td>8439.840820</td>\n",
              "      <td>8733.310547</td>\n",
              "      <td>9365.364258</td>\n",
              "      <td>10146.761719</td>\n",
              "      <td>12666.517578</td>\n",
              "      <td>12827.948242</td>\n",
              "      <td>15477.857422</td>\n",
              "      <td>20050.494141</td>\n",
              "      <td>24463.492188</td>\n",
              "      <td>24249.542969</td>\n",
              "      <td>23741.783203</td>\n",
              "      <td>27582.117188</td>\n",
              "      <td>31736.705078</td>\n",
              "      <td>34267.625000</td>\n",
              "      <td>35541.273438</td>\n",
              "      <td>41196.957031</td>\n",
              "      <td>42340.046875</td>\n",
              "      <td>41881.082031</td>\n",
              "      <td>47377.042969</td>\n",
              "      <td>50250.714844</td>\n",
              "      <td>52213.820312</td>\n",
              "      <td>52762.355469</td>\n",
              "      <td>52361.644531</td>\n",
              "      <td>51615.878906</td>\n",
              "      <td>48157.550781</td>\n",
              "      <td>54186.617188</td>\n",
              "      <td>51297.992188</td>\n",
              "      <td>49733.996094</td>\n",
              "      <td>52679.957031</td>\n",
              "      <td>53790.996094</td>\n",
              "      <td>53353.125000</td>\n",
              "      <td>49935.417969</td>\n",
              "      <td>52180.781250</td>\n",
              "      <td>49616.531250</td>\n",
              "      <td>48619.320312</td>\n",
              "      <td>53515.898438</td>\n",
              "      <td>54206.398438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 868 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Page  ...    2017-11-13\n",
              "0            2NE1_zh.wikipedia.org_all-access_spider  ...  54835.027344\n",
              "1             2PM_zh.wikipedia.org_all-access_spider  ...  53051.683594\n",
              "2              3C_zh.wikipedia.org_all-access_spider  ...  53472.882812\n",
              "3         4minute_zh.wikipedia.org_all-access_spider  ...  54516.679688\n",
              "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  ...  54206.398438\n",
              "\n",
              "[5 rows x 868 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cG2OMrwTJinY"
      },
      "source": [
        "key=pd.read_csv('/content/gdrive/MyDrive/Kaggle/key_2.csv.zip')\r\n",
        "submission=pd.read_csv('/content/gdrive/MyDrive/Kaggle/sample_submission_2.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cyatLqkIJk3U",
        "outputId": "39646d49-b75f-4dc6-9ad4-e432902ab361"
      },
      "source": [
        "key1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page</th>\n",
              "      <th>Id</th>\n",
              "      <th>Visits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>007_スペクター_ja.wikipedia.org_all-access_all-agen...</td>\n",
              "      <td>0b293039387a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>007_スペクター_ja.wikipedia.org_all-access_all-agen...</td>\n",
              "      <td>7114389dd824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>007_スペクター_ja.wikipedia.org_all-access_all-agen...</td>\n",
              "      <td>057b02ff1f09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>007_スペクター_ja.wikipedia.org_all-access_all-agen...</td>\n",
              "      <td>bd2aca21caa3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>007_スペクター_ja.wikipedia.org_all-access_all-agen...</td>\n",
              "      <td>c0effb42cdd5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Page            Id  Visits\n",
              "0  007_スペクター_ja.wikipedia.org_all-access_all-agen...  0b293039387a       0\n",
              "1  007_スペクター_ja.wikipedia.org_all-access_all-agen...  7114389dd824       0\n",
              "2  007_スペクター_ja.wikipedia.org_all-access_all-agen...  057b02ff1f09       0\n",
              "3  007_スペクター_ja.wikipedia.org_all-access_all-agen...  bd2aca21caa3       0\n",
              "4  007_スペクター_ja.wikipedia.org_all-access_all-agen...  c0effb42cdd5       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9swMantHatkU"
      },
      "source": [
        "id=key['Page'].values\r\n",
        "visits={} # In this we will store our predictions, keys are the name of the page and values are the predictions\r\n",
        "for i in range(data.shape[0]):\r\n",
        "    date = datetime.date(2017,9,13)\r\n",
        "    for j in range(62):\r\n",
        "        name=pages[i] + '_' + str(date)\r\n",
        "        visits[name]=new_data.at[i,str(date)]\r\n",
        "        date += datetime.timedelta(days=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lQPjF_jkLagL"
      },
      "source": [
        "for i in range(len(id)):\r\n",
        "    submission.at[i,'Visits']=visits[id[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDbwKPHvLakV"
      },
      "source": [
        "submission.to_csv('gbdt.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8gkyN_gtw91"
      },
      "source": [
        "![gbdt submission.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p76ixN5Q9wFS"
      },
      "source": [
        "<h1>LSTM+CNN</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GFmSL76hUMy"
      },
      "source": [
        "indices = np.random.permutation(data.shape[0])\r\n",
        "new_index=indices[:int(0.5*data.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHLlSYhyLewA"
      },
      "source": [
        "project=[]\r\n",
        "access=[]\r\n",
        "agent=[]\r\n",
        "language=[]\r\n",
        "for i in idx:\r\n",
        "  temp=pages[i].split(\".\")\r\n",
        "  project.append(temp[-2])\r\n",
        "  k=temp[-3].split(\"_\")\r\n",
        "  if k[-1]==\"commons\" or k[-1]==\"www\":\r\n",
        "    language.append(\"media\")\r\n",
        "  else:\r\n",
        "    language.append(k[-1])\r\n",
        "  t=temp[-1].split(\"_\")\r\n",
        "  access.append(t[1])\r\n",
        "  agent.append(t[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv1SXl6rQPk-"
      },
      "source": [
        "x_train=[]\r\n",
        "y_train=[]\r\n",
        "for i in (new_index):\r\n",
        "    k = np.array(data.iloc[i].values[-264:], dtype=int)\r\n",
        "    temp=np.log1p(k)\r\n",
        "    x_train.append(temp[:200]) \r\n",
        "    y_train.append(temp[200:264])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXHSauDIQPnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b81368-b365-4c07-9230-579da51de9c6"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72531"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7G1FSuQPpz"
      },
      "source": [
        "x=np.array(x_train).reshape(len(new_index),200,1)\r\n",
        "y=np.array(y_train).reshape(len(new_index),64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob8jU2JMpiTe",
        "outputId": "0259fafe-37fa-4663-c71b-8f4258b2b030"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72531, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T9FsCv2QPvh"
      },
      "source": [
        "x_train=x[:50000]\r\n",
        "y_train=y[:50000]\r\n",
        "x_test=x[50000:]\r\n",
        "y_test=y[50000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGZP5EyFQf_7"
      },
      "source": [
        "#label encoding is for lstm+embedding layers\r\n",
        "from sklearn.preprocessing import LabelEncoder,normalize\r\n",
        "enc_access= LabelEncoder()\r\n",
        "access_ohe=enc_access.fit_transform(np.array(access))\r\n",
        "enc_project= LabelEncoder()\r\n",
        "project_ohe=enc_project.fit_transform(np.array(project))\r\n",
        "enc_agent=LabelEncoder()\r\n",
        "agent_ohe=enc_agent.fit_transform(np.array(agent))\r\n",
        "enc_language= LabelEncoder()\r\n",
        "language_ohe=enc_language.fit_transform(np.array(language))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5jHgj5DQgCl"
      },
      "source": [
        "access_train=access_ohe[:50000] # Splitting into train ans test\r\n",
        "access_test=access_ohe[50000:]\r\n",
        "\r\n",
        "lang_train=language_ohe[:50000]\r\n",
        "lang_test=language_ohe[50000:]\r\n",
        "\r\n",
        "agent_train=agent_ohe[:50000]\r\n",
        "agent_test=agent_ohe[50000:]\r\n",
        "\r\n",
        "project_train=project_ohe[:80000]\r\n",
        "project_test=project_ohe[80000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4TNDf-aMUL3",
        "outputId": "faa2f957-1882-4020-f858-ec07803c274e"
      },
      "source": [
        "lang_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATq-ecQCQgFG"
      },
      "source": [
        "access_train=access_train.reshape(len(access_train),1)\r\n",
        "access_test=access_test.reshape(len(access_test),1)\r\n",
        "lang_train=lang_train.reshape(len(lang_train),1)\r\n",
        "lang_test=lang_test.reshape(len(lang_test),1)\r\n",
        "agent_train=agent_train.reshape(len(agent_train),1)\r\n",
        "agent_test=agent_test.reshape(len(agent_test),1)\r\n",
        "project_train=project_train.reshape(len(project_train),1)\r\n",
        "project_test=project_test.reshape(len(project_test),1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3JY1MvheuxZ"
      },
      "source": [
        "#one hot encoding is for lstm+cnn model\r\n",
        "from sklearn.preprocessing import OneHotEncoder,normalize\r\n",
        "enc_access= OneHotEncoder(sparse=False)\r\n",
        "access_ohe=enc_access.fit_transform(np.array(access).reshape(-1,1))\r\n",
        "enc_project= OneHotEncoder(sparse=False)\r\n",
        "project_ohe=enc_project.fit_transform(np.array(project).reshape(-1,1))\r\n",
        "enc_agent= OneHotEncoder(sparse=False)\r\n",
        "agent_ohe=enc_agent.fit_transform(np.array(agent).reshape(-1,1))\r\n",
        "enc_language= OneHotEncoder(sparse=False)\r\n",
        "language_ohe=enc_language.fit_transform(np.array(language).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8HbwytKQlq7"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Dense,Input,Activation,LSTM,Flatten,Conv1D,Conv2D,Embedding,Concatenate,Dropout,BatchNormalization,RepeatVector,TimeDistributed,concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypxKz2EUu_V9"
      },
      "source": [
        "#data stacking for lstm+cnn model\r\n",
        "x_tr=np.hstack((access_train,lang_train,agent_train,project_train))\r\n",
        "x_te=np.hstack((access_test,lang_test,agent_test,project_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_JxDEsFn1oj",
        "outputId": "82a97090-1c8d-4e59-f1cb-59717554353c"
      },
      "source": [
        "x_tr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 16, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDPXXvtaww5M",
        "outputId": "863cc535-3107-414c-d91b-74b52d1f0842"
      },
      "source": [
        "x_te.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28797, 16, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkyUycaJ1TQc"
      },
      "source": [
        "#reshaping the data for feeding in to model\r\n",
        "x_tr=np.expand_dims(x_tr,axis=2)\r\n",
        "x_te=np.expand_dims(x_te,axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzJ2XEPdvozV",
        "outputId": "49647d33-153b-4404-edfe-e5789fa9ae0f"
      },
      "source": [
        "from keras import regularizers \r\n",
        "input_layer=Input(shape=(x_train.shape[1],1))\r\n",
        "x=LSTM(100)(input_layer)\r\n",
        "flatten_1=Flatten()(x)\r\n",
        "input_layer_2=Input(shape=(16,1))\r\n",
        "con1D_N=Conv1D(filters=64, kernel_size=2, activation='relu')(input_layer_2)\r\n",
        "con1D_M=Conv1D(filters=32 ,kernel_size=2, activation='relu')(con1D_N)\r\n",
        "con1D_O=Conv1D(filters=16 ,kernel_size=2, activation='relu')(con1D_M)\r\n",
        "\r\n",
        "flatten_2=Flatten()(con1D_O)\r\n",
        "concate__layer=concatenate([flatten_1,flatten_2])\r\n",
        "dense_1 = Dense(1024,activation=\"relu\")(concate__layer)\r\n",
        "dense_2 = Dense(512,activation=\"relu\")(dense_1)\r\n",
        "dense_3=Dense(256,activation=\"relu\")(dense_2)\r\n",
        "output=Dense(64)(dense_3)\r\n",
        "model_3 = Model(inputs=[input_layer,input_layer_2],outputs=output)\r\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 16, 1)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 15, 64)       192         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 300, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 14, 32)       4128        conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          40800       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 13, 16)       1040        conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 100)          0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 208)          0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 308)          0           flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         316416      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          524800      dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 256)          131328      dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 64)           16448       dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,035,152\n",
            "Trainable params: 1,035,152\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XVUAz4v93VQU",
        "outputId": "6ae7f6a9-4e6b-46ee-c9a4-901ba34d41c3"
      },
      "source": [
        "optimizer=tf.keras.optimizers.Adam()\r\n",
        "model_3.compile(optimizer=optimizer, loss=\"mae\")\r\n",
        "model_3.fit([x_train,x_tr], y_train, validation_data=([x_test,x_te],y_test),epochs=70, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "1250/1250 [==============================] - 29s 17ms/step - loss: 0.5888 - val_loss: 0.3751\n",
            "Epoch 2/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3803 - val_loss: 0.3909\n",
            "Epoch 3/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3605 - val_loss: 0.3456\n",
            "Epoch 4/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3506 - val_loss: 0.3713\n",
            "Epoch 5/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3470 - val_loss: 0.3447\n",
            "Epoch 6/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3451 - val_loss: 0.3402\n",
            "Epoch 7/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3408 - val_loss: 0.3468\n",
            "Epoch 8/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3404 - val_loss: 0.3418\n",
            "Epoch 9/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3379 - val_loss: 0.3387\n",
            "Epoch 10/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3378 - val_loss: 0.3365\n",
            "Epoch 11/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3360 - val_loss: 0.3353\n",
            "Epoch 12/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3346 - val_loss: 0.3420\n",
            "Epoch 13/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3316 - val_loss: 0.3377\n",
            "Epoch 14/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3332 - val_loss: 0.3345\n",
            "Epoch 15/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3304 - val_loss: 0.3313\n",
            "Epoch 16/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3329 - val_loss: 0.3297\n",
            "Epoch 17/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3286 - val_loss: 0.3316\n",
            "Epoch 18/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3285 - val_loss: 0.3412\n",
            "Epoch 19/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3266 - val_loss: 0.3291\n",
            "Epoch 20/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3265 - val_loss: 0.3433\n",
            "Epoch 21/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3260 - val_loss: 0.3314\n",
            "Epoch 22/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3249 - val_loss: 0.3274\n",
            "Epoch 23/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3250 - val_loss: 0.3275\n",
            "Epoch 24/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3224 - val_loss: 0.3273\n",
            "Epoch 25/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3219 - val_loss: 0.3279\n",
            "Epoch 26/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3207 - val_loss: 0.3258\n",
            "Epoch 27/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3211 - val_loss: 0.3250\n",
            "Epoch 28/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3198 - val_loss: 0.3256\n",
            "Epoch 29/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3188 - val_loss: 0.3293\n",
            "Epoch 30/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3190 - val_loss: 0.3346\n",
            "Epoch 31/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3183 - val_loss: 0.3262\n",
            "Epoch 32/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3167 - val_loss: 0.3235\n",
            "Epoch 33/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3165 - val_loss: 0.3302\n",
            "Epoch 34/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3149 - val_loss: 0.3231\n",
            "Epoch 35/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3162 - val_loss: 0.3286\n",
            "Epoch 36/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3152 - val_loss: 0.3268\n",
            "Epoch 37/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3134 - val_loss: 0.3235\n",
            "Epoch 38/70\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 0.3130 - val_loss: 0.3339\n",
            "Epoch 39/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3123 - val_loss: 0.3281\n",
            "Epoch 40/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3114 - val_loss: 0.3271\n",
            "Epoch 41/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3122 - val_loss: 0.3232\n",
            "Epoch 42/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3109 - val_loss: 0.3295\n",
            "Epoch 43/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3104 - val_loss: 0.3219\n",
            "Epoch 44/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3097 - val_loss: 0.3222\n",
            "Epoch 45/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3265 - val_loss: 0.3345\n",
            "Epoch 46/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3188 - val_loss: 0.3264\n",
            "Epoch 47/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3147 - val_loss: 0.3287\n",
            "Epoch 48/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3106 - val_loss: 0.3260\n",
            "Epoch 49/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3121 - val_loss: 0.3259\n",
            "Epoch 50/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3107 - val_loss: 0.3227\n",
            "Epoch 51/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3091 - val_loss: 0.3542\n",
            "Epoch 52/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3369 - val_loss: 0.3281\n",
            "Epoch 53/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3189 - val_loss: 0.3248\n",
            "Epoch 54/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3119 - val_loss: 0.3253\n",
            "Epoch 55/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3120 - val_loss: 0.3247\n",
            "Epoch 56/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3083 - val_loss: 0.3224\n",
            "Epoch 57/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3068 - val_loss: 0.3204\n",
            "Epoch 58/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3044 - val_loss: 0.3218\n",
            "Epoch 59/70\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3050 - val_loss: 0.3213\n",
            "Epoch 60/70\n",
            " 801/1250 [==================>...........] - ETA: 6s - loss: 0.3017"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bdc2f7c892a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxf8SV2eebbO"
      },
      "source": [
        "key=pd.read_csv('/content/gdrive/MyDrive/Kaggle/key_2.csv.zip')\r\n",
        "submission=pd.read_csv('/content/gdrive/MyDrive/Kaggle/sample_submission_2.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6rJ0TR5ebeM"
      },
      "source": [
        "x_pred=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    k = np.array(data.iloc[i].values[-200:], dtype=int)\r\n",
        "    temp=np.log1p(k)\r\n",
        "    x_pred.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zXwj5Tvebj9"
      },
      "source": [
        "project=[]\r\n",
        "access=[]\r\n",
        "agent=[]\r\n",
        "language=[]\r\n",
        "for i in range(len(pages)):\r\n",
        "  temp=pages[i].split(\".\")\r\n",
        "  project.append(temp[-2])\r\n",
        "  k=temp[-3].split(\"_\")\r\n",
        "  if k[-1]==\"commons\" or k[-1]==\"www\":\r\n",
        "    language.append(\"media\")\r\n",
        "  else:\r\n",
        "    language.append(k[-1])\r\n",
        "  t=temp[-1].split(\"_\")\r\n",
        "  access.append(t[1])\r\n",
        "  agent.append(t[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5pVP0MMebna"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder,normalize\r\n",
        "enc_access= OneHotEncoder(sparse=False)\r\n",
        "access_ohe_test=enc_access.fit_transform(np.array(access).reshape(-1,1))\r\n",
        "enc_project= OneHotEncoder(sparse=False)\r\n",
        "project_ohe_test=enc_project.fit_transform(np.array(project).reshape(-1,1))\r\n",
        "enc_agent= OneHotEncoder(sparse=False)\r\n",
        "agent_ohe_test=enc_agent.fit_transform(np.array(agent).reshape(-1,1))\r\n",
        "enc_language= OneHotEncoder(sparse=False)\r\n",
        "language_ohe_test=enc_language.fit_transform(np.array(language).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoHPoqUkebrR"
      },
      "source": [
        "x_pred=np.array(x_pred).reshape(data.shape[0],200,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lI3c4IuebtT"
      },
      "source": [
        "from scipy.sparse import hstack\r\n",
        "x_pred=np.hstack((access_ohe_test,language_ohe_test,agent_ohe_test,project_ohe_test))\r\n",
        "x_pred=np.expand_dims(x_tr,axis=2)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABa1wwfkebw9"
      },
      "source": [
        "pred=model_3.predict([x_pred,x_tr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8FJjGmafEjg"
      },
      "source": [
        "import datetime\r\n",
        "id=key['Page'].values\r\n",
        "visits={}\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    date = datetime.date(2017,9,13)\r\n",
        "    for j in range(62):\r\n",
        "        name=pages[i] + '_' + str(date)\r\n",
        "        visits[name]=pred[i][j]\r\n",
        "        date += datetime.timedelta(days=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKllFjDXfEm4"
      },
      "source": [
        "for i in tqdm(range(len(id))):\r\n",
        "    submission.at[i,'Visits']=visits[id[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYmf8g_9fEqz"
      },
      "source": [
        "submission.to_csv('lstm_4.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRAodqknt3Nu"
      },
      "source": [
        "![lst+cnn.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76WRnorWfOVd"
      },
      "source": [
        "<h1>lstm+embedding </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPF5jUFbQlxE",
        "outputId": "0b9324d1-f36c-450e-9e99-c0e4317acf14"
      },
      "source": [
        "from keras import regularizers \r\n",
        "input_layer=Input(shape=(x_train.shape[1],x_train.shape[2]))\r\n",
        "x=LSTM(100)(input_layer)\r\n",
        "input_layer1=Input(shape=(access_train.shape[1],))\r\n",
        "x1=Embedding(input_dim=3,output_dim=3)(input_layer1)\r\n",
        "x1=Flatten()(x1)\r\n",
        "input_layer2=Input(shape=(lang_train.shape[1],))\r\n",
        "x2=Embedding(input_dim=9,output_dim=9)(input_layer2)\r\n",
        "x2=Flatten()(x2)\r\n",
        "input_layer3=Input(shape=(agent_train.shape[1],))\r\n",
        "x3=Embedding(input_dim=2,output_dim=2)(input_layer3)\r\n",
        "x3=Flatten()(x3)\r\n",
        "input_layer4=Input(shape=(project_train.shape[1],))\r\n",
        "concat=Concatenate()([x,x1,x2,x3])\r\n",
        "d2=Dense(256,activation='relu')(concat)\r\n",
        "d3=Dense(128,activation='relu')(d2)\r\n",
        "output=Dense(64)(d3)\r\n",
        "model=Model(inputs=[input_layer,input_layer1,input_layer2,input_layer3],outputs=output)\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 200, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 3)         9           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 9)         81          input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 2)         4           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          40800       input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 3)            0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 9)            0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 2)            0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 114)          0           lstm_1[0][0]                     \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 256)          29440       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          32896       dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           8256        dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 111,486\n",
            "Trainable params: 111,486\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-ESK1y6SRVn",
        "outputId": "be5fdc47-2d41-4f26-ac2f-52b13e5c77fc"
      },
      "source": [
        "optimizer=tf.keras.optimizers.Adam()\r\n",
        "model.compile(optimizer=optimizer, loss=\"mae\")\r\n",
        "model.fit([x_train,access_train,lang_train,agent_train], y_train, validation_data=([x_test,access_test,lang_test,agent_test],y_test),epochs=80, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "782/782 [==============================] - 18s 14ms/step - loss: 0.8131 - val_loss: 0.3772\n",
            "Epoch 2/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3810 - val_loss: 0.3657\n",
            "Epoch 3/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3643 - val_loss: 0.3518\n",
            "Epoch 4/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3516 - val_loss: 0.3457\n",
            "Epoch 5/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3484 - val_loss: 0.3443\n",
            "Epoch 6/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3470 - val_loss: 0.3431\n",
            "Epoch 7/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3448 - val_loss: 0.3576\n",
            "Epoch 8/80\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3449 - val_loss: 0.3372\n",
            "Epoch 9/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3419 - val_loss: 0.3403\n",
            "Epoch 10/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3403 - val_loss: 0.3416\n",
            "Epoch 11/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3394 - val_loss: 0.3412\n",
            "Epoch 12/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3380 - val_loss: 0.3634\n",
            "Epoch 13/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3365 - val_loss: 0.3474\n",
            "Epoch 14/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3392 - val_loss: 0.3329\n",
            "Epoch 15/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3370 - val_loss: 0.3369\n",
            "Epoch 16/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3353 - val_loss: 0.3386\n",
            "Epoch 17/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3347 - val_loss: 0.3370\n",
            "Epoch 18/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3342 - val_loss: 0.3320\n",
            "Epoch 19/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3334 - val_loss: 0.3432\n",
            "Epoch 20/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3344 - val_loss: 0.3460\n",
            "Epoch 21/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3359 - val_loss: 0.3313\n",
            "Epoch 22/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3312 - val_loss: 0.3418\n",
            "Epoch 23/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3332 - val_loss: 0.3296\n",
            "Epoch 24/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3310 - val_loss: 0.3312\n",
            "Epoch 25/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3287 - val_loss: 0.3292\n",
            "Epoch 26/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3290 - val_loss: 0.3502\n",
            "Epoch 27/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3319 - val_loss: 0.3314\n",
            "Epoch 28/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3273 - val_loss: 0.3342\n",
            "Epoch 29/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3253 - val_loss: 0.3283\n",
            "Epoch 30/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3279 - val_loss: 0.3295\n",
            "Epoch 31/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3255 - val_loss: 0.3309\n",
            "Epoch 32/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3272 - val_loss: 0.3291\n",
            "Epoch 33/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3267 - val_loss: 0.3288\n",
            "Epoch 34/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3261 - val_loss: 0.3293\n",
            "Epoch 35/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3236 - val_loss: 0.3339\n",
            "Epoch 36/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3233 - val_loss: 0.3296\n",
            "Epoch 37/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3235 - val_loss: 0.3279\n",
            "Epoch 38/80\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.3235 - val_loss: 0.3270\n",
            "Epoch 39/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3219 - val_loss: 0.3355\n",
            "Epoch 40/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3238 - val_loss: 0.3340\n",
            "Epoch 41/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3236 - val_loss: 0.3311\n",
            "Epoch 42/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3238 - val_loss: 0.3271\n",
            "Epoch 43/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3218 - val_loss: 0.3279\n",
            "Epoch 44/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3208 - val_loss: 0.3322\n",
            "Epoch 45/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3210 - val_loss: 0.3286\n",
            "Epoch 46/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3199 - val_loss: 0.3298\n",
            "Epoch 47/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3200 - val_loss: 0.3288\n",
            "Epoch 48/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3179 - val_loss: 0.3290\n",
            "Epoch 49/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3183 - val_loss: 0.3261\n",
            "Epoch 50/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3165 - val_loss: 0.3276\n",
            "Epoch 51/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3165 - val_loss: 0.3257\n",
            "Epoch 52/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3169 - val_loss: 0.3283\n",
            "Epoch 53/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3167 - val_loss: 0.3263\n",
            "Epoch 54/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3168 - val_loss: 0.3301\n",
            "Epoch 55/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3168 - val_loss: 0.3267\n",
            "Epoch 56/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3174 - val_loss: 0.3260\n",
            "Epoch 57/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3173 - val_loss: 0.3376\n",
            "Epoch 58/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3173 - val_loss: 0.3266\n",
            "Epoch 59/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3155 - val_loss: 0.3270\n",
            "Epoch 60/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3143 - val_loss: 0.3294\n",
            "Epoch 61/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3172 - val_loss: 0.3270\n",
            "Epoch 62/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3153 - val_loss: 0.3255\n",
            "Epoch 63/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3144 - val_loss: 0.3274\n",
            "Epoch 64/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3154 - val_loss: 0.3268\n",
            "Epoch 65/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3136 - val_loss: 0.3298\n",
            "Epoch 66/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3142 - val_loss: 0.3274\n",
            "Epoch 67/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3113 - val_loss: 0.3271\n",
            "Epoch 68/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3127 - val_loss: 0.3267\n",
            "Epoch 69/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3117 - val_loss: 0.3275\n",
            "Epoch 70/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3123 - val_loss: 0.3253\n",
            "Epoch 71/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3113 - val_loss: 0.3267\n",
            "Epoch 72/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3108 - val_loss: 0.3267\n",
            "Epoch 73/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3108 - val_loss: 0.3269\n",
            "Epoch 74/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3127 - val_loss: 0.3308\n",
            "Epoch 75/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3096 - val_loss: 0.3251\n",
            "Epoch 76/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3100 - val_loss: 0.3252\n",
            "Epoch 77/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3089 - val_loss: 0.3259\n",
            "Epoch 78/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3098 - val_loss: 0.3244\n",
            "Epoch 79/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3100 - val_loss: 0.3251\n",
            "Epoch 80/80\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3082 - val_loss: 0.3244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd7001054a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcaoIAydTGJP"
      },
      "source": [
        "key=pd.read_csv('/content/gdrive/MyDrive/Kaggle/key_2.csv.zip')\r\n",
        "submission=pd.read_csv('/content/gdrive/MyDrive/Kaggle/sample_submission_2.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwsy6ApbhfIf",
        "outputId": "5ed85b2e-55f2-4cbe-be60-e53eb9369899"
      },
      "source": [
        "x_pred=[]\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    k = np.array(data.iloc[i].values[-200:], dtype=int)\r\n",
        "    temp=np.log1p(k)\r\n",
        "    x_pred.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [01:09<00:00, 2093.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07CAdbpWU3iL"
      },
      "source": [
        "project=[]\r\n",
        "access=[]\r\n",
        "agent=[]\r\n",
        "language=[]\r\n",
        "for i in range(len(pages)):\r\n",
        "  temp=pages[i].split(\".\")\r\n",
        "  project.append(temp[-2])\r\n",
        "  k=temp[-3].split(\"_\")\r\n",
        "  if k[-1]==\"commons\" or k[-1]==\"www\":\r\n",
        "    language.append(\"media\")\r\n",
        "  else:\r\n",
        "    language.append(k[-1])\r\n",
        "  t=temp[-1].split(\"_\")\r\n",
        "  access.append(t[1])\r\n",
        "  agent.append(t[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uesxlohURqK"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder,normalize\r\n",
        "enc_access= LabelEncoder()\r\n",
        "access_ohe_test=enc_access.transform(np.array(access))\r\n",
        "enc_project= LabelEncoder()\r\n",
        "project_ohe_test=enc_project.transform(np.array(project))\r\n",
        "enc_agent=LabelEncoder()\r\n",
        "agent_ohe_test=enc_agent.transform(np.array(agent))\r\n",
        "enc_language= LabelEncoder()\r\n",
        "language_ohe_test=enc_language.transform(np.array(language))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0HFGhg-zy0L"
      },
      "source": [
        "x_pred=np.array(x_pred).reshape(data.shape[0],200,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Xbe7UX0FFO",
        "outputId": "b047713f-186d-4766-86e5-42fa17386b9c"
      },
      "source": [
        "x_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145063, 300, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBNLneFx_IRf",
        "outputId": "20bcf2fe-56a8-4b37-ce71-edc1578814f0"
      },
      "source": [
        "x_tr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145063, 16, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rV17Oil2zSY"
      },
      "source": [
        "pred=model.predict([x_pred,access_ohe_test,language_ohe_test,agent_ohe_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcviqGYQhlXj"
      },
      "source": [
        "pred=model_3.predict([x_pred,x_tr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJb4bAt0UW29",
        "outputId": "529594f5-e771-4fb0-f75b-6194bc8a7ebe"
      },
      "source": [
        "for i in tqdm(range(pred.shape[0])):\r\n",
        "    pred[i]=np.expm1(pred[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [00:00<00:00, 382606.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62YlZkoHUW4w",
        "outputId": "8e155f49-8136-47a7-b841-dc0da9fef98d"
      },
      "source": [
        "import datetime\r\n",
        "id=key['Page'].values\r\n",
        "visits={}\r\n",
        "for i in tqdm(range(data.shape[0])):\r\n",
        "    date = datetime.date(2017,9,13)\r\n",
        "    for j in range(62):\r\n",
        "        name=pages[i] + '_' + str(date)\r\n",
        "        visits[name]=pred[i][j]\r\n",
        "        date += datetime.timedelta(days=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145063/145063 [00:51<00:00, 2817.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwTBmHaTUW7y",
        "outputId": "3d62d080-aafa-4797-bd26-9180507a1db1"
      },
      "source": [
        "for i in tqdm(range(len(id))):\r\n",
        "    submission.at[i,'Visits']=visits[id[i]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8993906/8993906 [02:57<00:00, 50561.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxaCID-JUkSl"
      },
      "source": [
        "submission.to_csv('lstm_4.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE_XCLtnt6HZ"
      },
      "source": [
        "![submission.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t8Dcv5eGDhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb42e325-3cfd-485b-9733-b1f1716e7a59"
      },
      "source": [
        "from prettytable import PrettyTable\r\n",
        "x = PrettyTable()\r\n",
        "x = PrettyTable([\"Sno.\",\"Model\", \"Kaggle Score\"])\r\n",
        "x.add_row([4,'XgBoost',179.36])\r\n",
        "x.add_row([5,'LSTM+cnn',41.30])\r\n",
        "x.add_row([6,'LSTM+embedding',40.65])\r\n",
        "\r\n",
        "print(x)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----------------+--------------+\n",
            "| Sno. |     Model      | Kaggle Score |\n",
            "+------+----------------+--------------+\n",
            "|  4   |    XgBoost     |    179.36    |\n",
            "|  5   |    LSTM+cnn    |     41.3     |\n",
            "|  6   | LSTM+embedding |    40.65     |\n",
            "+------+----------------+--------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6CyTrauWVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}